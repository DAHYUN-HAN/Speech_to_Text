{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from soynlp.normalizer import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "와하하핫\n",
      "와하하핫\n",
      "와하하핫\n"
     ]
    }
   ],
   "source": [
    "print(repeat_normalize('와하하하하하하하하하핫', num_repeats=2))\n",
    "print(repeat_normalize('와하하하하하하핫', num_repeats=2))\n",
    "print(repeat_normalize('와하하하하핫', num_repeats=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'word_score_table' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-15095be18ebf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mword_score_table\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"반포한\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcohesion_forward\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'word_score_table' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "from soynlp import DoublespaceLineCorpus\n",
    "from soynlp.word import WordExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2016-10-20.txt', <http.client.HTTPMessage at 0x2191a597e80>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/lovit/soynlp/master/tutorials/2016-10-20.txt\", filename=\"2016-10-20.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30091"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = DoublespaceLineCorpus(\"2016-10-20.txt\")\n",
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training was done. used memory 0.736 Gb\n",
      "all cohesion probabilities was computed. # words = 223348\n",
      "all branching entropies was computed # words = 361598\n",
      "all accessor variety was computed # words = 361598\n"
     ]
    }
   ],
   "source": [
    "word_extractor = WordExtractor()\n",
    "word_extractor.train(corpus)\n",
    "word_score_table = word_extractor.extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08838002913645132"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_score_table[\"반포한\"].cohesion_forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('국제사회', '와'), ('우리', '의'), ('노력', '들로'), ('범죄', '를'), ('척결', '하자')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from soynlp.tokenizer import LTokenizer\n",
    "\n",
    "scores = {word:score.cohesion_forward for word, score in word_score_table.items()}\n",
    "l_tokenizer = LTokenizer(scores=scores)\n",
    "l_tokenizer.tokenize(\"국제사회와 우리의 노력들로 범죄를 척결하자\", flatten=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['국제사회', '와', '우리', '의', '노력', '들로', '범죄', '를', '척결', '하자']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from soynlp.tokenizer import MaxScoreTokenizer\n",
    "\n",
    "maxscore_tokenizer = MaxScoreTokenizer(scores=scores)\n",
    "maxscore_tokenizer.tokenize(\"국제사회와우리의노력들로범죄를척결하자\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "original = '안녕하세요 현준입니다 반가워요 오늘 제가 읽어 드릴 책은요 얼어 죽어도 아이스 아메리카노라는 책입니다. 얼죽아라고 하죠 얼죽아 읽는 동안 어 위로를 많이 받았습니다. 저와 같은 위로를 여러분들도 같이 느낄 수 있었으면 좋겠다 라는 마음에 이 책을 읽게 됐어요 읽어드릴게요 만족하지 못하면 외롭다 불만이 많은 사람들은 대부분의 잘못 들을 타인에게 돌리고 걱정이 많은 사람들은 쓸모없는 것까지 굳이 싸잡아 자신에게 돌린다 전자의 경우엔 화가 많고 후자의 경우엔 슬픔이 많다 그리고 둘 다 외롭다'\n",
    "new_original = original.replace(\" \", \"\")\n",
    "\n",
    "naver = '안녕하세요 현준입니다. 반가워요 오늘 제가 읽어드릴 책은요. 얼어죽어도 아이스 아메리카노라는 책입니다. 얼주가라고 하죠. 얼주가 읽는 동안 위로를 많이 받았습니다. 저와 같은 위로를 여러분들도 같이 느낄 수 있었으면 좋겠다. 라는 마음에 이 책을 읽게 됐어요. 읽어드릴게요 만족하지 못하면 외롭다. 불만이 많은 사람들은 대부분의 잘못들을 타인에게 돌리고. 걱정이 많은 사람들은 쓸모없는 것까지 그들이 싸잡아 자신에게 돌린다. 전자의 경우에는 화가 많고. 부자의 경우에는 슬픔이 많다. 그리고 둘 다 외롭다'\n",
    "new_naver = naver.replace(\" \", \"\")\n",
    "\n",
    "x1 = maxscore_tokenizer.tokenize(new_original)\n",
    "x2 = maxscore_tokenizer.tokenize(new_naver)\n",
    "\n",
    "sent = (' '.join(x1), ' '.join(x2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.7443153]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(sent) #문장 벡터화 진행\n",
    "cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2]) #첫번째와 두번째 문장 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('안녕하세요 현준 입니다 반가워요 오늘 제가 읽어 드릴책은요얼어 죽어도 아이 스 아메리카노 라는 책 입니다 .얼죽아 라고 하죠얼죽아 읽는 동안 어위로를 많이 받았습니다 .저와 같은 위로를 여러분 들도 같이 느낄 수 있었으면 좋겠다 라는 마음 에이 책을 읽게 됐어요 읽어 드릴게요 만족 하지 못하 면외롭다 불만이 많은 사람들 은 대부분의 잘못 들을 타인에게 돌리고 걱정 이 많은 사람들 은 쓸모없는 것 까지 굳이 싸잡아 자신에게 돌 린다 전자 의 경우 엔화가많고후자의 경우 엔 슬픔 이 많다 그리고 둘다외롭다',\n",
       " '안녕하세요 현준 입니다 .반가워요 오늘 제가 읽어 드릴책은요.얼어 죽어도 아이 스 아메리카노 라는 책 입니다 .얼주가 라고 하죠.얼주가 읽는 동안 위로를 많이 받았습니다 .저와 같은 위로를 여러분 들도 같이 느낄 수 있었으면 좋겠다 . 라는 마음 에이 책을 읽게 됐어요 . 읽어 드릴게요 만족 하지 못하 면외롭다. 불만이 많은 사람들 은 대부분의 잘못 들을 타인에게 돌리고 . 걱정 이 많은 사람들 은 쓸모없는 것 까지 그들이 싸잡아 자신에게 돌 린다 . 전자 의 경우에는 화가많고.부자의 경우에는 슬픔 이 많다 . 그리고 둘다외롭다')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.79997309]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = maxscore_tokenizer.tokenize(original)\n",
    "x2 = maxscore_tokenizer.tokenize(naver)\n",
    "\n",
    "sent = (' '.join(x1), ' '.join(x2))\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(sent) #문장 벡터화 진행\n",
    "cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2]) #첫번째와 두번째 문장 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('안녕하세요 현준 입니다 반가워요 오늘 제가 읽어 드릴 책은요 얼어 죽어도 아이 스 아메리카노 라는 책 입니다 . 얼죽아 라고 하죠 얼죽아 읽는 동안 어 위로를 많이 받았습니다 . 저와 같은 위로를 여러분 들도 같이 느낄 수 있었으면 좋겠다 라는 마음 에 이 책을 읽게 됐어요 읽어 드릴게요 만족 하지 못하 면 외롭다 불만이 많은 사람들 은 대부분의 잘못 들을 타인에게 돌리고 걱정 이 많은 사람들 은 쓸모없는 것 까지 굳이 싸잡아 자신에게 돌 린다 전자 의 경우 엔 화가 많고 후자의 경우 엔 슬픔 이 많다 그리고 둘 다 외롭다',\n",
       " '안녕하세요 현준 입니다 . 반가워요 오늘 제가 읽어 드릴 책은요. 얼어 죽어도 아이 스 아메리카노 라는 책 입니다 . 얼주가 라고 하죠. 얼주가 읽는 동안 위로를 많이 받았습니다 . 저와 같은 위로를 여러분 들도 같이 느낄 수 있었으면 좋겠다 . 라는 마음 에 이 책을 읽게 됐어요 . 읽어 드릴게요 만족 하지 못하 면 외롭다. 불만이 많은 사람들 은 대부분의 잘못 들을 타인에게 돌리고 . 걱정 이 많은 사람들 은 쓸모없는 것 까지 그들이 싸잡아 자신에게 돌 린다 . 전자 의 경우에는 화가 많고. 부자의 경우에는 슬픔 이 많다 . 그리고 둘 다 외롭다')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from difflib import SequenceMatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9289099526066351\n"
     ]
    }
   ],
   "source": [
    "ratio = SequenceMatcher(None, new_original, new_naver).ratio()\n",
    "print(ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "original2 = '나는 마음을 돌리고 다시 주저앉았다. 묵직한 발소리가 계단 열일곱 개를 올라 차츰 가까이에 왔다. 마침 내 방 문 앞에서 발소리가 딱 멈추고 곧이어 노크 소리가 났다. 예 들어오십시오 홈즈의 대답에 벌컥 문을 열고 방안으로 들어선 사람은 그리스 신화에 나오는 헤라클레스처럼 건장한 몸집에 위엄 있는 얼굴을 한 남자였다. 입은 옷 또한 무척이나 화려했다. 윗옷 소매와 깃 가장자리에 값진 아스트라칸 모피가 달려 있었으며 어깨에 걸친 청색 망토의 안감은 눈에 확 띄는 노란 비단이었다. 그리고 아름다운 에메랄드로 장식'\n",
    "new_original = original.replace(\" \", \"\")\n",
    "\n",
    "naver2 = '나는 마음을 돌리고 다시 주저앉았다. 묵직한 발소리가 계단 17개를 올라차츰 가까이에 왔다. 마침 내 방문 앞에서 발소리가 딱 멈추고. 곧이어 노크 소리가 났다. 들어오십시오 홍제의 대답에 벌컥 문을 열고 방 안으로 들어선 사람은. 그릇의 신화에 나오는 헤라클래스처럼 건장한 몸집에 위험이 있는 얼굴을 한 남자였다. 입은 옷 또한 무척이나 화려했다. 위도 소매와 기 가장자리에 값진 아스트라칸 모피가 달려 있었으며. 어깨에 걸친 청색 망토의 안감은 눈에 확 띄는 노란 비단이었다. 그리고 아름다운 에메랄드로 자식. 등'\n",
    "new_naver2 = naver.replace(\" \", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05328596802841918\n"
     ]
    }
   ],
   "source": [
    "ratio = SequenceMatcher(None, original, naver2).ratio()\n",
    "print(ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25\n"
     ]
    }
   ],
   "source": [
    "ratio = SequenceMatcher(None, 'abcd', 'dcba').ratio()\n",
    "print(ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
